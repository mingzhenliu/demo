#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SpecKit çŸ¥è¯†åº“åŠ è½½å™¨ v2.2
é…ç½®é©±åŠ¨æ¨¡å¼ï¼šä¸‰çº§é…ç½®åŠ è½½ï¼Œè¾“å‡ºå…³é”®çº¦æŸ
ç‰ˆæœ¬ï¼š2.2.0 | æ›´æ–°æ—¥æœŸï¼š2025-01-19
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ ¸å¿ƒæ”¹è¿›ï¼š
1. ä¸‰çº§é…ç½®åŠ è½½ï¼šL0(åŸºç¡€) â†’ L1(æ‰©å±•) â†’ æœ¬åœ°(è¦†ç›–)
2. é…ç½®å­˜æ”¾åœ¨ L0 çŸ¥è¯†åº“ä¸­ï¼ŒåŒæ­¥æ›´æ–°
3. è¾“å‡ºå…³é”®çº¦æŸåˆ°ç»ˆç«¯ï¼ˆç¡®ä¿ AI çœ‹åˆ°ï¼‰
4. æ”¯æŒ --read-content å‚æ•°ç›´æ¥è¾“å‡ºæ–‡æ¡£å†…å®¹
5. ä»…ä½¿ç”¨ Python æ ‡å‡†åº“ï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ–

é…ç½®åŠ è½½ä¼˜å…ˆçº§ï¼š
1. L0: .knowledge/upstream/L0-enterprise/speckit-config/knowledge-config.json (ä¼ä¸šçº§åŸºç¡€)
2. L1: .knowledge/upstream/L1-project/speckit-config/local-override.json (é¡¹ç›®æ‰©å±•ï¼Œå¯é€‰)
3. æœ¬åœ°: .specify/local-override.json (æœ¬åœ°è¦†ç›–ï¼Œå¯é€‰ï¼Œå‘åå…¼å®¹)
4. é—ç•™: .specify/knowledge-config.json (å‘åå…¼å®¹)
"""

import argparse
import glob
import json
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

from common import (
    get_repo_root,
    log_info,
    log_success,
    log_warn,
    log_error,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é…ç½®åŠ è½½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def deep_merge(base: Dict, override: Dict) -> Dict:
    """æ·±åº¦åˆå¹¶ä¸¤ä¸ªå­—å…¸ï¼Œoverride è¦†ç›– base çš„å€¼"""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result


def load_json_file(file_path: Path) -> Dict[str, Any]:
    """åŠ è½½å•ä¸ª JSON æ–‡ä»¶"""
    if not file_path.exists():
        return {}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        log_error(f"JSON è§£æé”™è¯¯ {file_path}: {e}")
        return {}


def load_json_config(repo_root: Path) -> Dict[str, Any]:
    """
    åŠ è½½çŸ¥è¯†åº“ JSON é…ç½® - ä¸‰çº§åŠ è½½

    åŠ è½½ä¼˜å…ˆçº§ï¼š
    1. L0 åŸºç¡€é…ç½® (å¿…é¡»å­˜åœ¨)
    2. L1 é¡¹ç›®æ‰©å±• (å¯é€‰)
    3. æœ¬åœ°è¦†ç›– (å¯é€‰)
    4. é—ç•™é…ç½® (å‘åå…¼å®¹)

    Returns:
        åˆå¹¶åçš„é…ç½®å­—å…¸
    """
    config = {}
    config_source = "unknown"

    # 1. L0 åŸºç¡€é…ç½® - ä¼ä¸šçº§æ ‡å‡†é…ç½®
    l0_config_path = repo_root / ".knowledge" / "upstream" / "L0-enterprise" / "speckit-config" / "knowledge-config.json"

    # 2. L1 é¡¹ç›®æ‰©å±• - é¡¹ç›®çº§è¦†ç›–
    l1_config_path = repo_root / ".knowledge" / "upstream" / "L1-project" / "speckit-config" / "local-override.json"

    # 3. æœ¬åœ°è¦†ç›– - ä¸´æ—¶è°ƒè¯•ç”¨
    local_config_path = repo_root / ".specify" / "local-override.json"

    # 4. é—ç•™é…ç½® - å‘åå…¼å®¹
    legacy_config_path = repo_root / ".specify" / "knowledge-config.json"

    # å°è¯•åŠ è½½ L0 é…ç½®
    if l0_config_path.exists():
        config = load_json_file(l0_config_path)
        config_source = "L0"
        if not config:
            log_error(f"L0 é…ç½®æ–‡ä»¶ä¸ºç©ºæˆ–è§£æå¤±è´¥: {l0_config_path}")
            return {}
    else:
        # L0 ä¸å­˜åœ¨ï¼Œå°è¯•é—ç•™é…ç½®
        log_warn("L0 é…ç½®ä¸å­˜åœ¨ï¼Œå°è¯•é—ç•™é…ç½®")
        if legacy_config_path.exists():
            config = load_json_file(legacy_config_path)
            config_source = "legacy"
            if not config:
                log_error("é—ç•™é…ç½®æ–‡ä»¶ä¸ºç©ºæˆ–è§£æå¤±è´¥")
                return {}
        else:
            log_error(f"çŸ¥è¯†åº“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {l0_config_path} æˆ– {legacy_config_path}")
            return {}

    # 2. åŠ è½½ L1 æ‰©å±•ï¼ˆå¯é€‰ï¼‰
    if l1_config_path.exists():
        l1_config = load_json_file(l1_config_path)
        if l1_config:
            config = deep_merge(config, l1_config)
            config_source += " + L1"

    # 3. åŠ è½½æœ¬åœ°è¦†ç›–ï¼ˆå¯é€‰ï¼‰
    if local_config_path.exists():
        local_config = load_json_file(local_config_path)
        if local_config:
            config = deep_merge(config, local_config)
            config_source += " + local"

    # è°ƒè¯•ä¿¡æ¯
    import os
    if os.environ.get('DEBUG_CONFIG'):
        log_info(f"é…ç½®æ¥æº: {config_source}")

    return config


def get_base_path(repo_root: Path, level: str, config: Dict[str, Any]) -> Path:
    """è·å–çŸ¥è¯†åº“åŸºç¡€è·¯å¾„"""
    sources = config.get('knowledge_sources', {})
    level_config = sources.get(level, {})
    rel_path = level_config.get('path', '')

    if not rel_path:
        # é»˜è®¤è·¯å¾„
        defaults = {
            'L0': '.knowledge/upstream/L0-enterprise',
            'L1': '.knowledge/upstream/L1-project',
            'L2': '.knowledge'
        }
        rel_path = defaults.get(level, '.knowledge')

    return repo_root / rel_path


def get_full_path(repo_root: Path, level: str, file_path: str, config: Dict[str, Any]) -> Path:
    """è·å–æ–‡ä»¶å®Œæ•´è·¯å¾„"""
    base_path = get_base_path(repo_root, level, config)
    return base_path / file_path


def estimate_tokens(file_path: Path) -> int:
    """è®¡ç®—æ–‡ä»¶ Token ä¼°ç®—ï¼ˆç²—ç•¥ï¼š1 Token â‰ˆ 4 å­—ç¬¦ï¼‰"""
    if file_path.is_file():
        try:
            chars = file_path.stat().st_size
            return chars // 4
        except OSError:
            return 0
    return 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¸å¿ƒåŠŸèƒ½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_command_config(config: Dict[str, Any], command: str, checklist_type: str = "") -> Dict[str, Any]:
    """è·å–å‘½ä»¤çš„çŸ¥è¯†åº“é…ç½®"""
    cmd_knowledge = config.get('command_knowledge', {})

    # å¤„ç† checklist çš„ç‰¹æ®Šç±»å‹
    if command == 'checklist' and checklist_type:
        checklist_config = cmd_knowledge.get('checklist', {})
        types = checklist_config.get('types', {})
        type_config = types.get(checklist_type, {})
        return {
            'description': type_config.get('description', f'{checklist_type} æ£€æŸ¥æ¸…å•'),
            'documents': type_config.get('documents', [])
        }

    # å¤„ç† feature-dev é˜¶æ®µ
    if command.startswith('feature-dev-') or command.startswith('fd-'):
        feature_dev = config.get('feature_dev', {})

        # æ˜ å°„çŸ­åç§°åˆ°å®Œæ•´é˜¶æ®µå
        phase_mapping = {
            'feature-dev-phase1': 'phase1_discovery',
            'fd-discovery': 'phase1_discovery',
            'feature-dev-phase2': 'phase2_exploration',
            'fd-exploration': 'phase2_exploration',
            'feature-dev-phase3': 'phase3_clarification',
            'fd-clarification': 'phase3_clarification',
            'feature-dev-phase4': 'phase4_architecture',
            'fd-architecture': 'phase4_architecture',
            'feature-dev-phase5': 'phase5_implementation',
            'fd-implementation': 'phase5_implementation',
            'feature-dev-phase6': 'phase6_review',
            'fd-review': 'phase6_review',
            'feature-dev-phase7': 'phase7_summary',
            'fd-summary': 'phase7_summary',
        }

        phase_key = phase_mapping.get(command)
        if phase_key:
            return feature_dev.get(phase_key, {})

    return cmd_knowledge.get(command, {})


def load_command_knowledge(
    repo_root: Path,
    command: str,
    checklist_type: str = "",
    output_format: str = "text",
    read_content: bool = False
) -> Tuple[bool, Optional[dict]]:
    """åŠ è½½å‘½ä»¤æ‰€éœ€çš„çŸ¥è¯†åº“"""

    config = load_json_config(repo_root)
    if not config:
        return False, {"error": "KNOW-004", "error_message": "çŸ¥è¯†åº“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥"}

    cmd_config = get_command_config(config, command, checklist_type)
    if not cmd_config:
        return False, {"error": "UNKNOWN_COMMAND", "error_message": f"æœªçŸ¥å‘½ä»¤: {command}"}

    documents: List[dict] = []
    has_error = False
    has_critical_error = False
    total_tokens = 0
    all_constraints: List[Dict[str, Any]] = []

    cmd_description = cmd_config.get('description', command)
    doc_list = cmd_config.get('documents', [])

    # æ”¶é›†æ‰€æœ‰çº¦æŸ
    for doc in doc_list:
        if doc.get('constraints'):
            all_constraints.append({
                'description': doc.get('description', doc.get('path')),
                'level': doc.get('level'),
                'critical': doc.get('critical', False),
                'constraints': doc.get('constraints', [])
            })

    # æ–‡æœ¬æ ¼å¼è¾“å‡º
    if output_format == "text":
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"å‘½ä»¤: /speckit.{command}")
        print(f"æè¿°: {cmd_description}")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()

        # è¾“å‡ºå…³é”®çº¦æŸï¼ˆè¿™æ˜¯é‡ç‚¹ï¼ç¡®ä¿ AI çœ‹åˆ°ï¼‰
        if all_constraints:
            print("âš ï¸  ã€å…³é”®çº¦æŸ - å¿…é¡»éµå®ˆã€‘")
            print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

            for item in all_constraints:
                level_icon = "ğŸ”´" if item['critical'] else "ğŸŸ¡"
                print(f"\n{level_icon} [{item['level']}] {item['description']}:")
                for constraint in item['constraints']:
                    print(f"   â€¢ {constraint}")

            print()
            print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print()

    # å¤„ç†æ–‡æ¡£
    for doc in doc_list:
        level = doc.get('level', 'L2')
        doc_path = doc.get('path', '')
        required = doc.get('required', False)
        critical = doc.get('critical', False)
        description = doc.get('description', '')
        glob_pattern = doc.get('glob_pattern')
        dynamic = doc.get('dynamic', False)

        # è·³è¿‡åŠ¨æ€åŠ è½½çš„æ–‡æ¡£ï¼ˆéœ€è¦è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼‰
        if dynamic and not glob_pattern:
            continue

        # å¤„ç† glob æ¨¡å¼
        if glob_pattern or '*' in doc_path:
            pattern = glob_pattern or doc_path
            base_path = get_base_path(repo_root, level, config)
            full_pattern = str(base_path / pattern)

            matched_files = glob.glob(full_pattern, recursive=True)

            for matched_file in matched_files:
                matched_path = Path(matched_file)
                if matched_path.is_file():
                    tokens = estimate_tokens(matched_path)
                    total_tokens += tokens

                    try:
                        rel_path = matched_path.relative_to(base_path)
                    except ValueError:
                        rel_path = matched_path.name

                    documents.append({
                        "level": level,
                        "path": str(rel_path),
                        "full_path": str(matched_path),
                        "description": description,
                        "status": "exists",
                        "required": required,
                        "critical": critical,
                        "tokens": tokens
                    })

                    if output_format == "text":
                        log_info(f"[{level}] {rel_path} ({tokens} tokens)")
                        print(f"       â””â”€ {description}")
        else:
            # å•ä¸ªæ–‡ä»¶
            full_path = get_full_path(repo_root, level, doc_path, config)

            status = "missing"
            tokens = 0

            if full_path.is_file():
                status = "exists"
                tokens = estimate_tokens(full_path)
                total_tokens += tokens

                if output_format == "text":
                    req_tag = "å¿…éœ€" if required else "å¯é€‰"
                    crit_tag = " âš ï¸ CRITICAL" if critical else ""
                    log_success(f"[{level}] {doc_path} ({req_tag}{crit_tag}, {tokens} tokens)")
                    print(f"       â””â”€ {description}")
            else:
                # å¤„ç†ç¼ºå¤±
                if level == "L0" and required:
                    has_error = True
                    if critical:
                        has_critical_error = True
                    if output_format == "text":
                        log_error(f"[{level}] {doc_path} - ç¼ºå¤± (CRITICAL)")
                        print(f"       â””â”€ {description}")
                elif level == "L1" and required:
                    if output_format == "text":
                        log_warn(f"[{level}] {doc_path} - ç¼ºå¤± (WARNING)")
                        print(f"       â””â”€ {description}")
                else:
                    if output_format == "text":
                        log_info(f"[{level}] {doc_path} - ç¼ºå¤± (è·³è¿‡)")

            documents.append({
                "level": level,
                "path": doc_path,
                "full_path": str(full_path),
                "description": description,
                "status": status,
                "required": required,
                "critical": critical,
                "tokens": tokens
            })

    # æ„å»ºç»“æœ
    result = {
        "command": command,
        "description": cmd_description,
        "status": "error" if has_error else "success",
        "has_critical_error": has_critical_error,
        "documents": documents,
        "constraints": all_constraints,
        "total_tokens": total_tokens,
        "doc_count": len(documents),
        "paths": {
            "required": [d["full_path"] for d in documents if d["required"] and d["status"] == "exists"],
            "optional": [d["full_path"] for d in documents if not d["required"] and d["status"] == "exists"],
            "missing": [d["full_path"] for d in documents if d["status"] == "missing"]
        }
    }

    if has_error:
        result["error_code"] = "KNOW-001"
        result["error_message"] = "L0 çŸ¥è¯†åº“æ–‡æ¡£ç¼ºå¤±ï¼Œæµç¨‹è¢«é˜»æ­¢"

    # è¾“å‡ºæ ¼å¼å¤„ç†
    if output_format == "json":
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print()
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"æ€»è®¡: {len(documents)} ä¸ªæ–‡æ¡£, çº¦ {total_tokens} tokens")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        if has_critical_error:
            log_error("âŒ æµç¨‹è¢«é˜»æ­¢ï¼šL0 CRITICAL æ–‡æ¡£ç¼ºå¤±")
            print()
            print("ä¸‹ä¸€æ­¥ï¼šè¯·ç¡®ä¿ L0 çŸ¥è¯†åº“æ–‡æ¡£å­˜åœ¨ï¼Œç„¶åé‡æ–°è¿è¡Œå‘½ä»¤ã€‚")
        elif has_error:
            log_error("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼šL0 å¿…éœ€æ–‡æ¡£ç¼ºå¤±")
        else:
            print()
            print("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸ")
            print()
            print("ğŸ“‹ éœ€è¦è¯»å–çš„æ–‡æ¡£åˆ—è¡¨ï¼š")
            for doc in documents:
                if doc["status"] == "exists":
                    print(f"   - {doc['full_path']}")

    # å¦‚æœéœ€è¦è¯»å–å†…å®¹
    if read_content and output_format == "text":
        print()
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("ğŸ“– æ–‡æ¡£å†…å®¹")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        for doc in documents:
            if doc["status"] == "exists":
                full_path = Path(doc["full_path"])
                print()
                print(f"### [{doc['level']}] {doc['path']}")
                print(f"### {doc['description']}")
                print("---")
                try:
                    content = full_path.read_text(encoding='utf-8')
                    # é™åˆ¶è¾“å‡ºé•¿åº¦
                    max_chars = 8000  # çº¦ 2000 tokens
                    if len(content) > max_chars:
                        content = content[:max_chars] + "\n\n... [å†…å®¹å·²æˆªæ–­] ..."
                    print(content)
                except Exception as e:
                    print(f"[è¯»å–é”™è¯¯: {e}]")
                print("---")

    return not has_error, result


def validate_knowledge_structure(repo_root: Path, output_format: str = "text") -> bool:
    """éªŒè¯çŸ¥è¯†åº“ç»“æ„"""
    config = load_json_config(repo_root)

    if output_format == "text":
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("çŸ¥è¯†åº“ç»“æ„éªŒè¯")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    sources = config.get('knowledge_sources', {})
    results = {}

    for level in ['L0', 'L1', 'L2']:
        level_config = sources.get(level, {})
        path = get_base_path(repo_root, level, config)

        if path.is_dir():
            results[level] = "ok"
            if output_format == "text":
                log_success(f"{level} {level_config.get('description', '')}: {path}")
        else:
            on_missing = level_config.get('on_missing', 'skip')
            results[level] = "missing"

            if on_missing == 'error':
                if output_format == "text":
                    log_error(f"{level} {level_config.get('description', '')}: {path} - ç¼ºå¤±")
            elif on_missing == 'warn':
                if output_format == "text":
                    log_warn(f"{level} {level_config.get('description', '')}: {path} - ç¼ºå¤±")
            else:
                if output_format == "text":
                    log_info(f"{level} {level_config.get('description', '')}: {path} - ç¼ºå¤± (è·³è¿‡)")

    if output_format == "json":
        print(json.dumps(results, ensure_ascii=False))

    return results.get('L0') != 'missing'


def list_commands(config: Dict[str, Any]):
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å‘½ä»¤"""
    print("å¯ç”¨å‘½ä»¤ï¼š")
    print()

    cmd_knowledge = config.get('command_knowledge', {})

    print("  SpecKit å‘½ä»¤ï¼š")
    for cmd, cfg in cmd_knowledge.items():
        desc = cfg.get('description', '')
        doc_count = len(cfg.get('documents', []))
        print(f"  {cmd:15} - {desc} ({doc_count} ä¸ªæ–‡æ¡£)")

    print()
    print("  Feature-Dev æ’ä»¶é˜¶æ®µï¼š")
    feature_dev = config.get('feature_dev', {})
    phase_names = {
        'phase1_discovery': 'fd-discovery',
        'phase2_exploration': 'fd-exploration',
        'phase3_clarification': 'fd-clarification',
        'phase4_architecture': 'fd-architecture',
        'phase5_implementation': 'fd-implementation',
        'phase6_review': 'fd-review',
        'phase7_summary': 'fd-summary',
    }

    for phase_key, short_name in phase_names.items():
        phase_cfg = feature_dev.get(phase_key, {})
        desc = phase_cfg.get('description', '')
        doc_count = len(phase_cfg.get('documents', []))
        print(f"  {short_name:15} - {desc} ({doc_count} ä¸ªæ–‡æ¡£)")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description='SpecKit çŸ¥è¯†åº“åŠ è½½å™¨ v2.0 - é…ç½®é©±åŠ¨æ¨¡å¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  python load-knowledge.py implement                 # åŠ è½½ implement å‘½ä»¤æ‰€éœ€çŸ¥è¯†åº“
  python load-knowledge.py implement --json          # JSON æ ¼å¼è¾“å‡º
  python load-knowledge.py implement --read-content  # è¾“å‡ºæ–‡æ¡£å†…å®¹
  python load-knowledge.py checklist --type security # åŠ è½½å®‰å…¨æ£€æŸ¥æ¸…å•çŸ¥è¯†åº“
  python load-knowledge.py validate                  # éªŒè¯çŸ¥è¯†åº“ç»“æ„
  python load-knowledge.py list                      # åˆ—å‡ºæ‰€æœ‰å¯ç”¨å‘½ä»¤

ç‰¹æ€§:
  - ä» .specify/knowledge-config.json è¯»å–é…ç½®
  - è¾“å‡ºå…³é”®çº¦æŸåˆ°ç»ˆç«¯ï¼ˆç¡®ä¿ AI çœ‹åˆ°ï¼‰
  - æ”¯æŒ --read-content ç›´æ¥è¾“å‡ºæ–‡æ¡£å†…å®¹
  - ä»…ä½¿ç”¨ Python æ ‡å‡†åº“ï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ–
'''
    )
    parser.add_argument('--json', '-j', action='store_true', dest='json_mode',
                        help='è¾“å‡º JSON æ ¼å¼')
    parser.add_argument('--type', '-t', dest='checklist_type', default='',
                        help='checklist ç±»å‹ (security/testing/api/coding)')
    parser.add_argument('--read-content', '-r', action='store_true', dest='read_content',
                        help='è¯»å–å¹¶è¾“å‡ºæ–‡æ¡£å†…å®¹')
    parser.add_argument('command', nargs='?', default='',
                        help='å‘½ä»¤åç§°æˆ– validate/list')

    args = parser.parse_args()
    output_format = "json" if args.json_mode else "text"

    repo_root = get_repo_root()
    config = load_json_config(repo_root)

    # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    if args.command == "validate":
        success = validate_knowledge_structure(repo_root, output_format)
        sys.exit(0 if success else 1)

    if args.command == "list":
        list_commands(config)
        sys.exit(0)

    if not args.command:
        parser.print_usage()
        sys.exit(1)

    # éªŒè¯å‘½ä»¤æ˜¯å¦æœ‰æ•ˆ
    cmd_config = get_command_config(config, args.command, args.checklist_type)
    if not cmd_config:
        log_error(f"æœªçŸ¥å‘½ä»¤: {args.command}")
        list_commands(config)
        sys.exit(1)

    # åŠ è½½çŸ¥è¯†åº“
    success, _ = load_command_knowledge(
        repo_root,
        args.command,
        args.checklist_type,
        output_format,
        args.read_content
    )

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
